{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "383f81ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pytesseract\n",
    "#import csv\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ultralytics import YOLO\n",
    "import textract\n",
    "#from PIL import Image\n",
    "#import matplotlib.pyplot as plt\n",
    "import keras_ocr\n",
    "import Levenshtein\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2de254ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking for C:\\Users\\Flam\\.keras-ocr\\craft_mlt_25k.h5\n",
      "WARNING:tensorflow:From C:\\Users\\Flam\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow\\python\\ops\\array_ops.py:5043: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n",
      "Looking for C:\\Users\\Flam\\.keras-ocr\\crnn_kurapan.h5\n"
     ]
    }
   ],
   "source": [
    "#Tesseract configuration\n",
    "custom_words = 'f_dictionnary_v1.txt'\n",
    "config = f'--psm 6 --user-words {custom_words}'\n",
    "pipeline = keras_ocr.pipeline.Pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "81c1e48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning strings\n",
    "def strip_string(my_string):\n",
    "    replacements = [('!', ''), ('?', ''),('|',''),(\"[\",\"\"),(\"]\",\"\"),(\"/\",\"\"),('\\\\',\"\"),('\\r',''),('\\'',''),('\"',''),('',''),(\"\\u200f\",\"\"),(\"\\u200e\",\"\"),(\"{\",\"\"),(\"}\",\"\"),(\"%\",\"\"),(\"~\",\"\"),(\",\",\".\"),(':','.'),(\";\",\".\"),('°',''),('+',''),('(',''),(')','')]\n",
    "    for char, replacement in replacements:\n",
    "        if char in my_string:\n",
    "            my_string = my_string.replace(char, replacement)\n",
    "    return my_string\n",
    "\n",
    "def strip_dates(my_string):\n",
    "    replacements = [('!', ''), ('?', ''),('|',''),(\"[\",\"\"),(\"]\",\"\"),(\"%\",\"\"),(\"\\u200f\",\"\"),(\"\\u200e\",\"\"),(\"{\",\"\"),(\"}\",\"\"),(\"&\",\"\")]\n",
    "    for char, replacement in replacements:\n",
    "        if char in my_string:\n",
    "            my_string = my_string.replace(char, replacement)\n",
    "    return my_string\n",
    "\n",
    "def prepare(my_string,flag):\n",
    "    if (flag!='paragraph2'):\n",
    "        tmp=strip_string(my_string)\n",
    "    else:\n",
    "        tmp=strip_dates(my_string)\n",
    "    tmp=tmp.split(\"\\n\")\n",
    "    while(\"\" in tmp):\n",
    "        tmp.remove(\"\")\n",
    "    tmp2=tmp\n",
    "    tmp3=tmp\n",
    "    if (flag=='tab'):\n",
    "        tmp2 = [i.replace(' ','') for i in tmp]\n",
    "        tmp3 = [i.replace('o','0') for i in tmp2]\n",
    "        #print(tmp3)\n",
    "        tmp4=' '.join(tmp3)\n",
    "        return (tmp4)\n",
    "    return(tmp3)\n",
    "\n",
    "def remove_substring_except_last(string, substring):\n",
    "    # Replace all occurrences of the substring except the last one with an empty string\n",
    "    new_string = string.replace(substring, \"\", string.count(substring)-1)\n",
    "    # Split the string at the last occurrence of the substring\n",
    "    parts = new_string.rsplit(substring, 1)\n",
    "    # Join the parts back together with the substring\n",
    "    return substring.join(parts)\n",
    "\n",
    "def reglage_montant(money):\n",
    "    for i in range(len(money)):\n",
    "        money[i]=remove_substring_except_last(money[i],'.')\n",
    "    return (money)\n",
    "\n",
    "def get_numbers(test_string):\n",
    "    letter = [x for x in test_string]\n",
    "    res = [i for i in letter if i.isdigit()]\n",
    "    result=''.join(res)\n",
    "    if (len(result)>0):\n",
    "        return result\n",
    "    else:\n",
    "        return (test_string)\n",
    "def containsNumber(value):\n",
    "    for character in value:\n",
    "        if character.isdigit():\n",
    "            return True\n",
    "    return False\n",
    "def number_correction(string):\n",
    "    corrected=[]\n",
    "    replacements = [(\"a\",\"0\"),(\"p\",\"0\"),(\"q\",\"0\"),(\"d\",\"0\"),(\"o\",\"0\"),(\"O\",\"0\"),('e','6')]\n",
    "    X=string.split(\" \")\n",
    "    for i in X:\n",
    "        letters=i\n",
    "        for char, replacement in replacements:\n",
    "            if char in letters:\n",
    "                letters = letters.replace(char, replacement)\n",
    "        corrected.append(letters)\n",
    "    ss=\" \".join(corrected)\n",
    "    return (ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57e3c74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correcting words with help of dictionnary\n",
    "def find_closest_word(word, dictionary_file):\n",
    "    smallest_distance = float('inf')\n",
    "    closest_word = \"\"\n",
    "\n",
    "    with open(dictionary_file,encoding='utf-8') as f:\n",
    "        words = [line.strip() for line in f]\n",
    "\n",
    "    for dict_word in words:\n",
    "        distance = Levenshtein.distance(word, dict_word)\n",
    "        if distance < smallest_distance:\n",
    "            smallest_distance = distance\n",
    "            closest_word = dict_word\n",
    "\n",
    "    return closest_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "105a0a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to enhance the contrast of image for better ocr result\n",
    "def enhance(im):\n",
    "    img = cv2.imread(im)\n",
    "    # converting to LAB color space\n",
    "    lab= cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    l_channel, a, b = cv2.split(lab)\n",
    "\n",
    "    # Applying CLAHE to L-channel\n",
    "    # feel free to try different values for the limit and grid size:\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))\n",
    "    cl = clahe.apply(l_channel)\n",
    "\n",
    "    # merge the CLAHE enhanced L-channel with the a and b channel\n",
    "    limg = cv2.merge((cl,a,b))\n",
    "\n",
    "    # Converting image from LAB Color model to BGR color spcae\n",
    "    enhanced_img = cv2.cvtColor(limg, cv2.COLOR_LAB2BGR)\n",
    "\n",
    "    # Stacking the original image with the enhanced image\n",
    "    #result = np.hstack((img, enhanced_img))\n",
    "    #cv2.imshow('Result', result)\n",
    "    #cv2.waitKey(0)\n",
    "    return enhanced_img"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cf3b19",
   "metadata": {},
   "source": [
    "## Treating type 1 invoices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "b232d70c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning and extracting data from para 1\n",
    "def extract_para1(para1):\n",
    "    parag=prepare(para1[0],'paragraph1')\n",
    "    LOIs=[parag[0],parag[1]]\n",
    "    #print(LOIs)\n",
    "    for LOI in LOIs:\n",
    "        loi=LOI.split()\n",
    "        for item in loi:\n",
    "            try:\n",
    "                n_facture=int(item)\n",
    "            except:\n",
    "                n_facture=0\n",
    "            if(n_facture > 0 ):\n",
    "                return (n_facture)\n",
    "    return(0)\n",
    "    #print(LOI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c295c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning and extracting data from para 2\n",
    "def fix_date(date):\n",
    "    return find_closest_word(date,'dates.txt')\n",
    "def extract_para2(para2):\n",
    "    parag=prepare(para2[0],'paragraph2')\n",
    "    clean=[]\n",
    "    for i in parag:\n",
    "        if len(i)>3:\n",
    "            clean.append(i)\n",
    "    #print(clean)\n",
    "    mois=clean[0].split()\n",
    "    ref=clean[2].split()\n",
    "    #print(ref)\n",
    "    for item in ref:\n",
    "        try:\n",
    "            ref_=int(item)\n",
    "        except:\n",
    "            ref_=0\n",
    "        if(ref_ != 0 ):\n",
    "            break\n",
    "    for item in mois:\n",
    "        res = any(chr.isdigit() for chr in item)\n",
    "        if (res):\n",
    "            mois_=item\n",
    "            break\n",
    "    mois_=fix(mois_)\n",
    "    #print(ref_)\n",
    "    #print(mois_)\n",
    "    return([mois_,ref_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28cc6290",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting bounding boxes cordinates and their labels\n",
    "def boxes_labels(results,x,y,h,w,c):\n",
    "    bbox=results[0].boxes.boxes\n",
    "    bbox=bbox.cpu().numpy()\n",
    "    boxes=results[0].boxes.xyxy\n",
    "    for i,box in enumerate(boxes):\n",
    "        box=box.cpu().numpy()\n",
    "        print(\"fragment \",i,\" :\",box)\n",
    "        x.append(int(box[0]))\n",
    "        y.append(int(box[1]))\n",
    "        h.append(int(box[3]-y[i]))\n",
    "        w.append(int(box[2]-x[i]))\n",
    "        c.append(bbox[i][5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95877154",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing ROIs in a liste\n",
    "def crop_image(x,y,h,w):\n",
    "    cropped=[]\n",
    "    for (X,Y,H,W) in zip(x,y,h,w):\n",
    "        cropped.append(img[Y:Y+H, X:X+W])\n",
    "    print(\"cropped images: \",len(cropped))\n",
    "    return (cropped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3236c55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#to avoid the presence of multi instance from classes\n",
    "def singilarity(cropped,c,classes,images):\n",
    "   # images=[]\n",
    "    for (img,C) in zip(cropped,c):\n",
    "        try:\n",
    "            i=classes.index(C)\n",
    "        except:\n",
    "            i=-1\n",
    "        if i<0 :\n",
    "            classes.append(C)\n",
    "            images.append(img)\n",
    "        else :\n",
    "            if len(img)>len(images[i]) :\n",
    "                images[i]=img\n",
    "    print('number of images:',len(images),'number of classes',len(classes))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "18552426",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return the best result from three ocr results\n",
    "def best_res(string1,string2,string3):\n",
    "    # Define the three OCR strings\n",
    "    flag=False\n",
    "    if (string1==''):\n",
    "        flag=True\n",
    "        string1='0123456789.'\n",
    "    if(string2==''):\n",
    "        if (flag==False):\n",
    "            flag=True\n",
    "            string2='0123456789.'\n",
    "    if(string3==''):\n",
    "        if (flag==False):\n",
    "            flag=True\n",
    "            string3='0123456789.'\n",
    "    ocr_strings = [string1,string2,string3]\n",
    "    #print('st1:',string1,'st2:',string2,'st3:',string3)\n",
    "    # Calculate the average Levenshtein distance between each OCR string and the other two strings\n",
    "    avg_distances = []\n",
    "    for i in range(len(ocr_strings)):\n",
    "        total_distance = 0\n",
    "        for j in range(len(ocr_strings)):\n",
    "            if i != j:\n",
    "                total_distance += Levenshtein.distance(ocr_strings[i], ocr_strings[j])\n",
    "        avg_distance = total_distance / 2\n",
    "        avg_distances.append(avg_distance)\n",
    "\n",
    "    # Determine the most accurate result based on the average distances\n",
    "    #if min(avg_distances) < 4:\n",
    "    index = avg_distances.index(min(avg_distances))\n",
    "    if len(ocr_strings[index])>0:\n",
    "        return (ocr_strings[index])\n",
    "    else:\n",
    "        return('error')\n",
    "    #else:\n",
    "        #return ('not reliable')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "cf30ee3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_ocr(ocr_im,f,check=False):\n",
    "    res_keras=[]\n",
    "    corrected=[]\n",
    "    res_tes=[]\n",
    "    tt=cv2.imread(ocr_im)\n",
    "    if (f == 'ar'):\n",
    "        res_tess=pytesseract.image_to_string(tt,config=config,lang='ara')\n",
    "        #res_tes=prepare(res_tes,'tab')\n",
    "        print(res_tess)\n",
    "        res_tess=res_tess.split('\\n')\n",
    "        for x in res_tess:\n",
    "            if len(x)>1:\n",
    "                res_tes.append(x)\n",
    "        print(res_tes)\n",
    "        corrected=[]\n",
    "        for t in res_tes:\n",
    "            line=''\n",
    "            tmp=t.split(\" \")\n",
    "            for i in tmp :\n",
    "                if(containsNumber(i)):\n",
    "                    line+=i+' '\n",
    "                else :\n",
    "                    line+=find_closest_word(i, \"arabic.txt\")+' '\n",
    "            corrected.append(line)\n",
    "        #print(corrected)\n",
    "        return (corrected)\n",
    "    elif (f == '*'):\n",
    "        res_tes=pytesseract.image_to_string(tt,config=config,lang='ara')\n",
    "        res_tes=prepare(res_tes,'tab')\n",
    "        if (\"تقدير\" not in res_tes):\n",
    "            res_opus=textract.process(ocr_im,method='ocropus')\n",
    "            res_opus=res_opus.decode(\"utf-8\")\n",
    "            res_opus=prepare(res_opus,'tab')\n",
    "            predictions = pipeline.recognize([tt])\n",
    "            for prediction in predictions[0]:\n",
    "                res_keras=' '.join(prediction[0])\n",
    "                res_keras=number_correction(res_keras)\n",
    "            best=best_res(res_keras,res_tes,res_opus)\n",
    "            best_s=best.split()\n",
    "            return (best_s)\n",
    "        else :\n",
    "            return (res_tes.split())\n",
    "    else:\n",
    "        res_tes=pytesseract.image_to_string(tt,config=config)\n",
    "        res_tes=prepare(res_tes,'tab')\n",
    "        res_tes=number_correction(res_tes)\n",
    "        print(res_tes)\n",
    "        res_opus=textract.process(ocr_im,method='ocropus')\n",
    "        res_opus=res_opus.decode(\"utf-8\")\n",
    "        res_opus=prepare(res_opus,'tab')\n",
    "        res_opus=number_correction(res_opus)\n",
    "        print(res_opus)\n",
    "        predictions = pipeline.recognize([tt])\n",
    "        for prediction in predictions[0]:\n",
    "            res_keras.append(prepare(prediction[0],'tab'))\n",
    "        res_keras=' '.join(res_keras)\n",
    "        if (check==True):\n",
    "            if(\".\" not in res_keras):\n",
    "                res_keras=''\n",
    "        print(res_keras)\n",
    "        best=best_res(res_tes,res_opus,res_keras)\n",
    "        best_s=best.split()\n",
    "        return (best_s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbe7970a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv2' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[1;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#Loading the image on which we are going to perfom ocr\u001b[39;00m\n\u001b[0;32m      2\u001b[0m image\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mD1/22.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 3\u001b[0m img\u001b[38;5;241m=\u001b[39m\u001b[43mcv2\u001b[49m\u001b[38;5;241m.\u001b[39mimread(image,\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m      4\u001b[0m img\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv2' is not defined"
     ]
    }
   ],
   "source": [
    "#Loading the image on which we are going to perfom ocr\n",
    "image='D1/18.jpg'\n",
    "img=cv2.imread(image,0)\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4c0eb542",
   "metadata": {},
   "outputs": [],
   "source": [
    "#results2_tab = cellss(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "c8e6c919",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.0.22  Python-3.9.12 torch-1.13.1 CUDA:0 (NVIDIA GeForce GTX 1650, 4096MiB)\n",
      "Model summary (fused): 168 layers, 11126745 parameters, 0 gradients, 28.4 GFLOPs\n",
      "image 1/1 C:\\Users\\Flam\\Desktop\\Stage WCT\\D1\\18.jpg: 640x480 1 paragraph1, 1 paragraph2, 1 table, 21.0ms\n",
      "Speed: 3.0ms pre-process, 21.0ms inference, 42.0ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "# Load a model\n",
    "cells = YOLO(\"weights/cells_v5.pt\")# load the table cells detection model\n",
    "global_model= YOLO(\"weights/global_v2.pt\")    #load the global detection model\n",
    "\n",
    "# detecting the 3 main region of interests within the invoice\n",
    "results_global = global_model(image)  # predict on an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "6febca57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fragment  0  : [         20         173         652         418]\n",
      "fragment  1  : [         43         484        1240         782]\n",
      "fragment  2  : [        661         168        1233         414]\n",
      "cropped images:  3\n",
      "number of images: 3 number of classes 3\n"
     ]
    }
   ],
   "source": [
    "#Extracting bounding boxes and ROI from the global model\n",
    "x=[]\n",
    "y=[]\n",
    "h=[]\n",
    "w=[]\n",
    "c=[]\n",
    "cropped=[]\n",
    "boxes_labels(results_global,x,y,h,w,c)\n",
    "cropped=crop_image(x,y,h,w)\n",
    "classes=[]\n",
    "images=[]\n",
    "singilarity(cropped,c,classes,images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "34672579",
   "metadata": {},
   "outputs": [],
   "source": [
    "#performing OCR on the two paragraphs above the table\n",
    "ocr_results=[]\n",
    "for C,img in zip(classes,images):\n",
    "    if (C != 2):\n",
    "        ocr_results.append([pytesseract.image_to_string(img,config=config),int(C)])\n",
    "    else :\n",
    "        cv2.imwrite('sliced.jpg', img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9c552f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ocr_results:\n",
    "    if (i[1]==1):\n",
    "        n_facture=extract_para1(i)\n",
    "    else :\n",
    "        mois_ref=extract_para2(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "bf1a02eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "834102022404"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_facture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "c6488330",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0: 160x640 1 consommation, 1 libele, 1 montant, 1 month, 97.1ms\n",
      "Speed: 363.4ms pre-process, 97.1ms inference, 3.0ms postprocess per image at shape (1, 3, 640, 640)\n",
      "image 1/1 C:\\Users\\Flam\\Desktop\\Stage WCT\\D1\\18.jpg: 640x480 1 consommation, 1 libele, 1 montant, 1 month, 194.4ms\n",
      "Speed: 1.9ms pre-process, 194.4ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "img=cv2.imread('sliced.jpg')\n",
    "results_tab = cells(img)\n",
    "#results_tab2 = cells(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "7b251493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fragment  0  : [        273          59         426         203]\n",
      "fragment  1  : [        472          59         602         209]\n",
      "fragment  2  : [        878          56         945         198]\n",
      "fragment  3  : [        954          54        1187         200]\n",
      "cropped images:  4\n",
      "number of images: 4 number of classes 4\n"
     ]
    }
   ],
   "source": [
    "#Extracting bounding boxes and ROI from the table model\n",
    "x=[]\n",
    "y=[]\n",
    "h=[]\n",
    "w=[]\n",
    "c=[]\n",
    "cropped=[]\n",
    "boxes_labels(results_tab,x,y,h,w,c)\n",
    "cropped=crop_image(x,y,h,w)\n",
    "classes=[]\n",
    "images=[]\n",
    "singilarity(cropped,c,classes,images)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "1d9b8d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#storing cropped images locally\n",
    "exceptions=[0,0,0,0,0]\n",
    "try:\n",
    "    cv2.imwrite('mont.jpg', images[classes.index(2)])\n",
    "except:\n",
    "    exceptions[2]=1\n",
    "try:\n",
    "    cv2.imwrite('cons.jpg', images[classes.index(0)])\n",
    "except:\n",
    "    exceptions[0]=1\n",
    "try:\n",
    "    cv2.imwrite('indexe.jpg', images[classes.index(4)])\n",
    "except:\n",
    "    exceptions[4]=1\n",
    "try:\n",
    "    cv2.imwrite('month.jpg', images[classes.index(3)])\n",
    "except:\n",
    "    exceptions[3]=1\n",
    "try:\n",
    "    \n",
    "    cv2.imwrite('title.jpg', images[classes.index(1)])\n",
    "    cv2.imwrite('title2.jpg',enhance('title.jpg'))\n",
    "except:\n",
    "    exceptions[1]=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "d7ed6da0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 1]"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exceptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a00050f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21557\n",
      "21557\n",
      "21557\n",
      "*5 33 643155\n",
      "ءة 33 53000\n",
      "\n",
      "['*5 33 643155', 'ءة 33 53000']\n",
      "006 006\n",
      "00é 006\n",
      "096 096\n",
      "8387.664 46.200\n",
      "8387.664 46.200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if(exceptions[4]==0):\n",
    "    indexe=perform_ocr('indexe.jpg','*')\n",
    "else:\n",
    "    indexe=['error', 'error']\n",
    "if(exceptions[0]==0):\n",
    "    consommation=perform_ocr('cons.jpg','en')\n",
    "else:\n",
    "    consommation=['0' ,'0']\n",
    "if(exceptions[1]==0):\n",
    "    titles=perform_ocr('title2.jpg','ar')\n",
    "else:\n",
    "    titles=['error' ,'error']\n",
    "if(exceptions[3]==0):\n",
    "    month=perform_ocr('month.jpg','en')\n",
    "else:\n",
    "    month=['error','error'] \n",
    "if(exceptions[2]==0):\n",
    "    montant=perform_ocr('mont.jpg','en',check=True)\n",
    "else:\n",
    "    montant=['0.000','0.000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "1d293f68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['006', '006']"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "ea60d2e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_title =[]\n",
    "s_month=[]\n",
    "s_indexe =[]\n",
    "s_consommation =[]\n",
    "s_montant =[]\n",
    "i1,i2,i3,i4,i5 = len(titles)-1,len(month)-1,len(indexe)-1,len(consommation)-1,len(montant)-1\n",
    "flag=0\n",
    "somme=0\n",
    "if len(consommation)<=len(titles)/2:\n",
    "    while((min(i1,i2,i3,i4,i5)>-1)):\n",
    "        if(i1 % 2==1):\n",
    "            #print('working1')\n",
    "            i1-=1\n",
    "            i2-=1\n",
    "            somme+=float(montant[i5])\n",
    "            i5-=1\n",
    "        else:\n",
    "            #print('working2')\n",
    "            s_title.append(titles[i1])\n",
    "            s_month.append(month[i2])\n",
    "            s_indexe.append(indexe[i3])\n",
    "            s_consommation.append(consommation[i4])\n",
    "            somme+=float(montant[i5])\n",
    "            s_montant.append(somme)\n",
    "            somme=0\n",
    "            i1,i2,i3,i4,i5 = [v - 1 for v in (i1,i2,i3,i4,i5)]\n",
    "else:\n",
    "    while((min(i1,i2,i3,i4)>-1)and(i5> -2)):\n",
    "        if (\"قسط\" in titles[i1]):\n",
    "            flag = 1\n",
    "            somme += float(montant[i5])\n",
    "            i1-=1\n",
    "            i5-=1\n",
    "            i4-=1\n",
    "        else :\n",
    "            if (flag == 0):\n",
    "                s_title.append(titles[i1])\n",
    "                s_month.append(month[i2])\n",
    "                s_indexe.append(indexe[i3])\n",
    "                s_consommation.append(consommation[i4])\n",
    "                s_montant.append(montant[i5])\n",
    "                i5-=1\n",
    "            else  :\n",
    "                s_title.append(titles[i1])\n",
    "                s_month.append(month[i2])\n",
    "                s_indexe.append(indexe[i3])\n",
    "                s_consommation.append(consommation[i4])\n",
    "                s_montant.append(somme)\n",
    "                somme=0\n",
    "                flag=0\n",
    "            i1,i2,i3,i4 = [v - 1 for v in (i1,i2,i3,i4)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b0d1620c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8118abeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "93488cc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Type</th>\n",
       "      <th>Months</th>\n",
       "      <th>NV indexe</th>\n",
       "      <th>consommation</th>\n",
       "      <th>montant</th>\n",
       "      <th>n_facture</th>\n",
       "      <th>reference</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>*5 33 643155</td>\n",
       "      <td>006</td>\n",
       "      <td>error</td>\n",
       "      <td>21557</td>\n",
       "      <td>8433.864</td>\n",
       "      <td>834102022404</td>\n",
       "      <td>588469060</td>\n",
       "      <td>10/2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Type Months NV indexe consommation   montant     n_facture  \\\n",
       "0  *5 33 643155     006     error        21557  8433.864  834102022404   \n",
       "\n",
       "   reference     date  \n",
       "0  588469060  10/2022  "
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(list(zip(s_title,s_month,s_indexe,s_consommation,s_montant)),columns =['Type', 'Months', 'NV indexe','consommation','montant'])\n",
    "df['n_facture']=n_facture\n",
    "df['reference']=mois_ref[1]\n",
    "df['date']=mois_ref[0]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c91ac19f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['312.000', '192.000', '532.800', '71.162', '1699.558']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "montant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "433b2ba1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "492\n",
      "100\n"
     ]
    }
   ],
   "source": [
    "tt=cv2.imread('mont.jpg')\n",
    "res_keras=[]\n",
    "predictions = pipeline.recognize([tt])\n",
    "for prediction in predictions[0]:\n",
    "    print(prediction[0])\n",
    "    res_keras.append(prediction[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fdea15ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['4182', '1600', '800', '1600', '182', '2702']"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "7ac458fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'182'"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0][4][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7c16959e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[         59,         106],\n",
       "       [         97,         106],\n",
       "       [         97,         121],\n",
       "       [         59,         121]], dtype=float32)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "7fbcc426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r\n",
      "\n",
      "p02\n"
     ]
    }
   ],
   "source": [
    "ocr_im='month.jpg'\n",
    "res_keras=[]\n",
    "res_kerass=''\n",
    "tt=cv2.imread(ocr_im)\n",
    "res_tes=pytesseract.image_to_string(ocr_im,config=config)\n",
    "res_tes=prepare(res_tes,'tab')\n",
    "print(res_tes)\n",
    "res_opus=textract.process(ocr_im,method='ocropus')\n",
    "res_opus=res_opus.decode(\"utf-8\")\n",
    "res_opus=prepare(res_opus,'tab')\n",
    "print(res_opus)\n",
    "predictions = pipeline.recognize([tt])\n",
    "for prediction in predictions[0]:\n",
    "    res_keras.append(prepare(prediction[0],'tab'))\n",
    "    res_kerass=' '.join(res_keras)\n",
    "print(res_kerass)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7ac105cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "il\n",
      "\n",
      "002 0q2\n",
      "st1: il st2: 012.3456789.. st3: 002 0q2\n"
     ]
    }
   ],
   "source": [
    "titles=perform_ocr('month.jpg','en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f63580",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "0384c3e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "3ced84a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "نأءة42572729 ناءة42 220921540 10\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "25a0ecd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "نأءة 42 572729\n",
      "\n",
      "نلاءة 42\n",
      "\n",
      "ا 0 22092154\n",
      "10\n",
      "\n",
      "/\n",
      "\n",
      "['نأءة 42 572729', 'نلاءة 42', 'ا 0 22092154', '10']\n"
     ]
    }
   ],
   "source": [
    "cv2.imwrite('exe.jpg', enhanced_img)\n",
    "titles=perform_ocr('exe.jpg','ar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a47660ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd1e1b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
